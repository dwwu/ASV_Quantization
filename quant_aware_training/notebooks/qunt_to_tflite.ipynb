{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import tensorflow as tf\n",
    "from tdnn_model import make_tdnn_model, tdnn_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from kears model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tdnn_config('M')\n",
    "eval_model = make_tdnn_model(config, n_labels=1211)\n",
    "eval_model.load_weights(tf.train.latest_checkpoint(\"../training/quant_1/M/M\"))\n",
    "eval_model.save(\"save_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tdnn_model import StatPooling\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model_file(\"save_model.h5\",\n",
    "                                                          input_shapes={'conv2d_input':(1, 500, 1, 65)},\n",
    "                                                          custom_objects={'StatPooling':StatPooling})\n",
    "converter.inference_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "open(\"tflite_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(\"tflite_model.tflite\")\n",
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## from frozen graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConverterError",
     "evalue": "TOCO failed. See console for info.\n2019-06-28 02:42:19.654584: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 175 operators, 315 arrays (0 quantized)\n2019-06-28 02:42:19.655917: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 142 operators, 268 arrays (0 quantized)\n2019-06-28 02:42:19.657503: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 142 operators, 268 arrays (0 quantized)\n2019-06-28 02:42:19.658616: I tensorflow/lite/toco/graph_transformations/identify_dilated_conv.cc:202] Replaced sub-network with Dilated Conv2D op outputting \"conv2d_1/Conv2D\".\n2019-06-28 02:42:19.661691: I tensorflow/lite/toco/graph_transformations/identify_dilated_conv.cc:202] Replaced sub-network with Dilated Conv2D op outputting \"conv2d_2/Conv2D\".\n2019-06-28 02:42:19.667714: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 16 operators, 33 arrays (1 quantized)\n2019-06-28 02:42:19.672198: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 15 operators, 32 arrays (1 quantized)\n2019-06-28 02:42:19.672328: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 14 operators, 30 arrays (1 quantized)\n2019-06-28 02:42:19.672421: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 14 operators, 30 arrays (1 quantized)\n2019-06-28 02:42:19.672460: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 14 operators, 30 arrays (1 quantized)\n2019-06-28 02:42:19.672512: F tensorflow/lite/toco/tooling_util.cc:1724] Array re_lu/Relu, which is an input to the Conv operator producing the output array re_lu_1/Relu, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\nFatal Python error: Aborted\n\nCurrent thread 0x00007f2b7ee9f700 (most recent call first):\n  File \"/home/muncok/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 33 in execute\n  File \"/home/muncok/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/absl/app.py\", line 251 in _run_main\n  File \"/home/muncok/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/absl/app.py\", line 300 in run\n  File \"/home/muncok/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\n  File \"/home/muncok/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 59 in main\n  File \"/home/muncok/anaconda3/envs/tf_nightly/bin/toco_from_protos\", line 10 in <module>\nAborted (core dumped)\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-29873993fb39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantized_input_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'conv2d_input'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m127\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtflite_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quant_aware.tflite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m           \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m           \u001b[0mdebug_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_debug_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m           **converter_kwargs)\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       result = _toco_convert_graph_def(\n",
      "\u001b[0;32m~/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, *args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m   data = toco_convert_protos(model_flags.SerializeToString(),\n\u001b[1;32m    406\u001b[0m                              \u001b[0mtoco_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                              input_data.SerializeToString())\n\u001b[0m\u001b[1;32m    408\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str)\u001b[0m\n\u001b[1;32m    170\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m       raise ConverterError(\n\u001b[0;32m--> 172\u001b[0;31m           \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\n\u001b[0m\u001b[1;32m    173\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# Must manually cleanup files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConverterError\u001b[0m: TOCO failed. See console for info.\n2019-06-28 02:42:19.654584: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 175 operators, 315 arrays (0 quantized)\n2019-06-28 02:42:19.655917: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 142 operators, 268 arrays (0 quantized)\n2019-06-28 02:42:19.657503: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 142 operators, 268 arrays (0 quantized)\n2019-06-28 02:42:19.658616: I tensorflow/lite/toco/graph_transformations/identify_dilated_conv.cc:202] Replaced sub-network with Dilated Conv2D op outputting \"conv2d_1/Conv2D\".\n2019-06-28 02:42:19.661691: I tensorflow/lite/toco/graph_transformations/identify_dilated_conv.cc:202] Replaced sub-network with Dilated Conv2D op outputting \"conv2d_2/Conv2D\".\n2019-06-28 02:42:19.667714: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 16 operators, 33 arrays (1 quantized)\n2019-06-28 02:42:19.672198: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 15 operators, 32 arrays (1 quantized)\n2019-06-28 02:42:19.672328: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 14 operators, 30 arrays (1 quantized)\n2019-06-28 02:42:19.672421: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 14 operators, 30 arrays (1 quantized)\n2019-06-28 02:42:19.672460: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 14 operators, 30 arrays (1 quantized)\n2019-06-28 02:42:19.672512: F tensorflow/lite/toco/tooling_util.cc:1724] Array re_lu/Relu, which is an input to the Conv operator producing the output array re_lu_1/Relu, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\nFatal Python error: Aborted\n\nCurrent thread 0x00007f2b7ee9f700 (most recent call first):\n  File \"/home/muncok/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 33 in execute\n  File \"/home/muncok/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/absl/app.py\", line 251 in _run_main\n  File \"/home/muncok/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/absl/app.py\", line 300 in run\n  File \"/home/muncok/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\n  File \"/home/muncok/anaconda3/envs/tf_nightly/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 59 in main\n  File \"/home/muncok/anaconda3/envs/tf_nightly/bin/toco_from_protos\", line 10 in <module>\nAborted (core dumped)\n\n\n"
     ]
    }
   ],
   "source": [
    "ckpt_dir = '../training/quant_1/M/'\n",
    "model_size = 'M'\n",
    "batch_size = 32\n",
    "\n",
    "config = tdnn_config(model_size)\n",
    "converter = tf.lite.TFLiteConverter.from_frozen_graph(\n",
    "    os.path.join(ckpt_dir, 'frozen_model.pb'), ['conv2d_input'],\n",
    "    ['dense/BiasAdd'], {'conv2d_input': (batch_size, 500, 1, 65)}\n",
    ")\n",
    "\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.inference_type = tf.uint8\n",
    "converter.quantized_input_stats = {'conv2d_input':(128, 127)}\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(os.path.join(ckpt_dir, 'quant_aware.tflite'), 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(os.path.join(ckpt_dir, 'quant_aware.tflite'))\n",
    "interpreter.get_tensor_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "toco \\\n",
    "  --graph_def_file=../training/quant_1/M/frozen_model.pb \\\n",
    "  --output_file=tflite_model.tflite \\\n",
    "  --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\n",
    "  --inference_type=QUANTIZED_UINT8 \\\n",
    "  --input_shape=\"1,500, 1,65\" \\\n",
    "  --input_array=conv2d_input \\\n",
    "  --output_array=dense/BiasAdd \\\n",
    "  --std_dev_value=128 --mean_value=128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
